{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0046b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da49bcdf",
   "metadata": {},
   "source": [
    "=== Chargement des variables d‚Äôenvironnement ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c99452",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "BASE_DIR = os.getenv(\"BASE_DIR\")\n",
    "DATA_PROCESSED = os.getenv(\"DATA_PROCESSED\")\n",
    "DATA_REPORT = os.getenv(\"DATA_REPORT\")\n",
    "\n",
    "INPUT_PATH = os.path.join(DATA_PROCESSED, \"export_sentiment_analysis.csv\")\n",
    "OUTPUT_PATH = os.path.join(DATA_PROCESSED, \"export_clean_data.csv\")\n",
    "GRAPH_PATH = os.path.join(DATA_REPORT, \"report_clean_data.png\")\n",
    "CSV_REPORT_PATH = os.path.join(DATA_PROCESSED, \"stats_clean_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c807b6c",
   "metadata": {},
   "source": [
    "=== Fonctions de nettoyage ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aac2a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return np.nan\n",
    "    text = re.sub(r'(?<!\\w)(http\\S+|www\\S+|https\\S+)(?!\\w)', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def count_emojis(text):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    return sum(1 for c in text if c in emoji.EMOJI_DATA)\n",
    "\n",
    "def is_emoji_only(text):\n",
    "    if pd.isna(text) or not text.strip():\n",
    "        return False\n",
    "    cleaned = re.sub(r'[^\\w\\s,.!?]', '', text)\n",
    "    return len(cleaned.strip()) == 0 and any(c in emoji.EMOJI_DATA for c in text)\n",
    "\n",
    "def handle_duplicates_missing(df):\n",
    "    df['commentaire_clean'] = df['commentaire'].apply(clean_text)\n",
    "    duplicates = df.duplicated(subset=['commentaire_clean'], keep='first')\n",
    "    print(f\"‚Üí Doublons textuels d√©tect√©s : {duplicates.sum()}\")\n",
    "    df = df.drop_duplicates(subset=['commentaire_clean'], keep='first')\n",
    "    return df.drop(columns=['commentaire_clean'])\n",
    "\n",
    "def handle_outliers(df, stats_log):\n",
    "    if 'commentaire' not in df.columns:\n",
    "        return df\n",
    "    df['comment_length'] = df['commentaire'].str.len().fillna(0)\n",
    "    stats = df['comment_length'].describe()\n",
    "    print(\"‚Üí Statistiques des longueurs de commentaire :\")\n",
    "    print(stats)\n",
    "    stats_log.append(stats.to_dict())\n",
    "    q1 = df['comment_length'].quantile(0.01)\n",
    "    q99 = df['comment_length'].quantile(0.99)\n",
    "    initial = len(df)\n",
    "    df = df[(df['comment_length'] >= q1) & (df['comment_length'] <= q99)]\n",
    "    print(f\"‚Üí Commentaires conserv√©s apr√®s filtre : {len(df)}/{initial} ({(len(df)/initial):.2%})\")\n",
    "    return df.drop(columns=['comment_length'])\n",
    "\n",
    "def create_metrics(df):\n",
    "    print(\"‚Üí Calcul des m√©triques sur les commentaires\")\n",
    "    df['nb_mots'] = df['commentaire'].apply(lambda x: len(str(x).split()))\n",
    "    df['nb_emojis'] = df['commentaire'].apply(count_emojis)\n",
    "    df['longueur_commentaire'] = df['commentaire'].apply(lambda x: len(str(x)))\n",
    "    return df\n",
    "\n",
    "def handle_emoji_only(df):\n",
    "    print(\"‚Üí D√©tection des commentaires compos√©s uniquement d‚Äôemojis...\")\n",
    "    df['emoji_only'] = df['commentaire'].apply(is_emoji_only)\n",
    "    count = df['emoji_only'].sum()\n",
    "    print(f\"‚Üí Commentaires uniquement emojis supprim√©s : {count}\")\n",
    "    df = df[~df['emoji_only']]\n",
    "    return df.drop(columns=['emoji_only'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49aa99b",
   "metadata": {},
   "source": [
    "=== Fonction principale ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434aa12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        df = pd.read_csv(INPUT_PATH, dtype={'note_commentaire': str})\n",
    "        print(f\"‚úÖ Donn√©es charg√©es : {len(df)} lignes\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur de chargement : {str(e)}\")\n",
    "        return\n",
    "\n",
    "    expected_cols = ['auteur', 'date', 'commentaire', 'note_commentaire']\n",
    "    if missing := [col for col in expected_cols if col not in df.columns]:\n",
    "        print(f\"‚ùå Colonnes manquantes : {missing}\")\n",
    "        return\n",
    "\n",
    "    etapes = []\n",
    "    lignes_restantes = []\n",
    "    stats_details = []\n",
    "    \n",
    "    steps = [\n",
    "        (\"Nettoyage initial\", lambda x: x.assign(commentaire=x['commentaire'].apply(clean_text))),\n",
    "        (\"Gestion des valeurs manquantes\", lambda x: x.dropna(subset=['commentaire'])),\n",
    "        (\"Suppression des doublons\", handle_duplicates_missing),\n",
    "        (\"Ajout des m√©triques\", create_metrics),\n",
    "        (\"Filtrage des outliers\", lambda x: handle_outliers(x, stats_details)),\n",
    "        (\"Suppression des commentaires emojis-only\", handle_emoji_only)\n",
    "    ]\n",
    "\n",
    "    for name, step in steps:\n",
    "        try:\n",
    "            print(f\"\\n=== √âtape : {name} ===\")\n",
    "            before = len(df)\n",
    "            df = step(df)\n",
    "            after = len(df)\n",
    "            print(f\"‚Üí Lignes restantes apr√®s '{name}' : {after} (perte : {before - after})\")\n",
    "            etapes.append(name)\n",
    "            lignes_restantes.append(after)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur dans l'√©tape {name} : {str(e)}\")\n",
    "            return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c46d124",
   "metadata": {},
   "source": [
    "    # === Sauvegarde des donn√©es nettoy√©es ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353973b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    df.to_csv(OUTPUT_PATH, index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623bc709",
   "metadata": {},
   "source": [
    "    # === G√©n√©ration du graphique PNG ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46f3387",
   "metadata": {},
   "outputs": [],
   "source": [
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(etapes, lignes_restantes, marker=\"o\", linestyle=\"-\", color=\"royalblue\")\n",
    "    plt.title(\"√âvolution du nombre de lignes apr√®s chaque √©tape de nettoyage\")\n",
    "    plt.xlabel(\"√âtapes de nettoyage\")\n",
    "    plt.ylabel(\"Nombre de lignes restantes\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.xticks(rotation=30, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(GRAPH_PATH, dpi=300)\n",
    "    print(f\"\\nüìä Graphique g√©n√©r√© : {GRAPH_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa40e0fe",
   "metadata": {},
   "source": [
    "    # === Rapport statistique au format CSV ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d87f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "    rows_stats = []\n",
    "    for i, etape in enumerate(etapes):\n",
    "        row = {\n",
    "            \"√©tape\": etape,\n",
    "            \"lignes_restantes\": lignes_restantes[i],\n",
    "            \"perte_depuis_etape_prec\": lignes_restantes[i-1] - lignes_restantes[i] if i > 0 else 0\n",
    "        }\n",
    "        if i == 4 and stats_details:  # Ajoute les stats de longueur\n",
    "            row.update(stats_details[0])  # count, mean, std, min, 25%, 50%, 75%, max\n",
    "        rows_stats.append(row)\n",
    "\n",
    "    df_report = pd.DataFrame(rows_stats)\n",
    "    df_report.to_csv(CSV_REPORT_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"üìÅ Rapport CSV g√©n√©r√© : {CSV_REPORT_PATH}\")\n",
    "    print(f\"\\n‚úÖ Donn√©es finales sauvegard√©es dans : {OUTPUT_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
