{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed482ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from dotenv import load_dotenv\n",
    "from dateutil import parser\n",
    "\n",
    "def resolve_env_vars(value, env_dict):\n",
    "    if not value:\n",
    "        return value\n",
    "    pattern = re.compile(r\"\\$\\{([^}]+)\\}\")\n",
    "    matches = pattern.findall(value)\n",
    "    for var in matches:\n",
    "        if var in env_dict:\n",
    "            value = value.replace(f\"${{{var}}}\", env_dict[var])\n",
    "    return value\n",
    "\n",
    "load_dotenv()\n",
    "env_vars = dict(os.environ)\n",
    "\n",
    "base_dir = env_vars.get(\"BASE_DIR\", os.path.dirname(os.path.abspath(__file__)))\n",
    "base_dir = resolve_env_vars(base_dir, env_vars)\n",
    "\n",
    "data_raw_trustpilot = resolve_env_vars(env_vars.get(\"DATA_RAW_TRUSTPILOT\"), env_vars)\n",
    "if not data_raw_trustpilot:\n",
    "    data_raw_trustpilot = os.path.join(base_dir, \"data\", \"trustpilot\")\n",
    "\n",
    "log_dir = resolve_env_vars(env_vars.get(\"LOG_DIR\"), env_vars)\n",
    "if not log_dir:\n",
    "    log_dir = os.path.join(base_dir, \"log\")\n",
    "\n",
    "os.makedirs(data_raw_trustpilot, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "log_file = os.path.join(log_dir, f\"scraping_trustpilot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.FileHandler(log_file, encoding=\"utf-8\"), logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "class TrustpilotScraper:\n",
    "    def __init__(self, domain, max_pages=30):\n",
    "        self.original_domain = domain.lower().strip()\n",
    "        self.domain = re.sub(r\"\\.[a-z]{2,}$\", \"\", self.original_domain)\n",
    "        self.domain_dir = os.path.join(data_raw_trustpilot, self.domain)\n",
    "        os.makedirs(self.domain_dir, exist_ok=True)\n",
    "        self.max_pages = max_pages\n",
    "        self.ua = UserAgent()\n",
    "        self.session = self._init_session()\n",
    "        self.last_page_path = os.path.join(self.domain_dir, \"derniere_page.txt\")\n",
    "        self.info_data = None\n",
    "        self.last_successful_page = 0\n",
    "\n",
    "    def _init_session(self):\n",
    "        session = requests.Session()\n",
    "        retry = Retry(total=5, backoff_factor=1, status_forcelist=[500,502,503,504])\n",
    "        adapter = HTTPAdapter(max_retries=retry)\n",
    "        session.mount('https://', adapter)\n",
    "        return session\n",
    "\n",
    "    def _headers(self):\n",
    "        return {\n",
    "            \"User-Agent\": self.ua.random,\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "            \"Accept-Language\": \"fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "            \"Referer\": \"https://www.google.com/\"\n",
    "        }\n",
    "\n",
    "    def _load_last_page(self):\n",
    "        if os.path.exists(self.last_page_path):\n",
    "            try:\n",
    "                page = int(open(self.last_page_path, \"r\", encoding=\"utf-8\").read().strip())\n",
    "                logging.info(f\"Reprise Ã  partir de la page {page + 1}\")\n",
    "                return page + 1\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Erreur lecture {self.last_page_path} : {e}\")\n",
    "        return 1\n",
    "\n",
    "    def _save_last_page(self, page):\n",
    "        try:\n",
    "            with open(self.last_page_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(str(page))\n",
    "            self.last_successful_page = page\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Erreur sauvegarde {self.last_page_path} : {e}\")\n",
    "\n",
    "    def _extract_json_ld(self, soup):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
