{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc0d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e34290",
   "metadata": {},
   "source": [
    "Chargement des variables d'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c84c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = os.path.join(os.path.dirname(__file__), '../../.env')\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "BASE_DIR = os.getenv(\"BASE_DIR\")\n",
    "LOG_DIR = os.getenv(\"LOG_DIR\")\n",
    "TRUSTPILOT_DATA_DIR = os.path.join(BASE_DIR, \"data\", \"trustpilot\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4bedbb",
   "metadata": {},
   "source": [
    "Configuration du logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fab7536",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "log_filename = os.path.join(LOG_DIR, \"scraping_trustpilot.log\")\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename, encoding=\"utf-8\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136750d1",
   "metadata": {},
   "source": [
    "Fonction principale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9832d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_trustpilot(societe_domaine):\n",
    "    societe = societe_domaine.split(\".\")[0].lower()\n",
    "    now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    societe_dir = os.path.join(TRUSTPILOT_DATA_DIR, societe)\n",
    "    os.makedirs(societe_dir, exist_ok=True)\n",
    "\n",
    "    derniere_page_path = os.path.join(societe_dir, \"derniere_page.txt\")\n",
    "    history_path = os.path.join(societe_dir, \"history.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14969d7",
   "metadata": {},
   "source": [
    "    # Détection de la page de démarrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc50132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    start_page = 1\n",
    "    if os.path.exists(derniere_page_path):\n",
    "        with open(derniere_page_path, \"r\") as f:\n",
    "            try:\n",
    "                start_page = int(f.read().strip()) + 1\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    logging.info(f\"Lancement scraping : société = {societe} | start_page = {start_page}\")\n",
    "\n",
    "    avis_list = []\n",
    "    nb_pages = 0\n",
    "\n",
    "    for page in range(start_page, start_page + 10):  # Limité à 10 pages pour test\n",
    "        url = f\"https://fr.trustpilot.com/review/{societe_domaine}?page={page}\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        avis_elements = soup.find_all(\"section\", {\"data-qa\": \"review\"})\n",
    "\n",
    "        if not avis_elements:\n",
    "            break  # Fin des pages\n",
    "\n",
    "        avis_page = []\n",
    "        for avis in avis_elements:\n",
    "            titre = avis.find(\"h2\")\n",
    "            texte = avis.find(\"p\")\n",
    "            note = avis.find(\"div\", class_=\"star-rating_starRating__4rrcf\").get(\"class\", [])\n",
    "            date = avis.find(\"time\").get(\"datetime\") if avis.find(\"time\") else \"\"\n",
    "\n",
    "            avis_page.append({\n",
    "                \"titre\": titre.text.strip() if titre else \"\",\n",
    "                \"commentaire\": texte.text.strip() if texte else \"\",\n",
    "                \"note\": len(note) - 2,  # Hack simple pour étoile\n",
    "                \"date\": date\n",
    "            })\n",
    "\n",
    "        avis_list.extend(avis_page)\n",
    "        nb_pages += 1\n",
    "\n",
    "        logging.info(f\"Page {page} | URL: {url} | Avis : {len(avis_page)}\")\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832962fb",
   "metadata": {},
   "source": [
    "    # Aucun avis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4ccdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if not avis_list:\n",
    "        logging.warning(\"Aucun avis trouvé. Fin du script.\")\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9888c4",
   "metadata": {},
   "source": [
    "    # Sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243d80a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    scrap_dirname = f\"scrap_{societe}_{now}\"\n",
    "    scrap_dir = os.path.join(societe_dir, scrap_dirname)\n",
    "    os.makedirs(scrap_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5359c163",
   "metadata": {},
   "source": [
    "    # CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c316c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    csv_path = os.path.join(scrap_dir, f\"{societe}_commentaires_{now}.csv\")\n",
    "    pd.DataFrame(avis_list).to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59525535",
   "metadata": {},
   "source": [
    "    # JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46916b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    json_path = os.path.join(scrap_dir, f\"{societe}_commentaires_{now}.json\")\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(avis_list, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c08f5a",
   "metadata": {},
   "source": [
    "    # Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82392f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "    xlsx_path = os.path.join(scrap_dir, f\"{societe}_commentaires_{now}.xlsx\")\n",
    "    pd.DataFrame(avis_list).to_excel(xlsx_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf17825",
   "metadata": {},
   "source": [
    "    # Informations générales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7741df",
   "metadata": {},
   "outputs": [],
   "source": [
    "    txt_path = os.path.join(scrap_dir, f\"{societe}_informations_generales_{now}.txt\")\n",
    "    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Société : {societe_domaine}\\n\")\n",
    "        f.write(f\"Nombre total d'avis : {len(avis_list)}\\n\")\n",
    "        f.write(f\"Nombre de pages scrapées : {nb_pages}\\n\")\n",
    "        f.write(f\"Heure : {datetime.now()}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a08b263",
   "metadata": {},
   "source": [
    "    # Mise à jour du fichier derniere_page.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbd9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    with open(derniere_page_path, \"w\") as f:\n",
    "        f.write(str(start_page + nb_pages - 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffb1985",
   "metadata": {},
   "source": [
    "    # Ajout au fichier history.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0794f8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    with open(history_path, \"a\") as f:\n",
    "        f.write(f\"{now} | {scrap_dirname} | {len(avis_list)} avis\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ba0309",
   "metadata": {},
   "source": [
    "    # Affichage utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab5c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Données sauvegardées dans : {scrap_dir}\")\n",
    "    print(\"\\nArborescence du répertoire :\")\n",
    "    print(f\"├── derniere_page.txt\")\n",
    "    print(f\"├── history.txt\")\n",
    "    print(f\"└── {scrap_dirname}\")\n",
    "    for f in os.listdir(scrap_dir):\n",
    "        print(f\"    ├── {f}\")\n",
    "\n",
    "    logging.info(f\"Données sauvegardées dans : {scrap_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42790a7b",
   "metadata": {},
   "source": [
    "Lancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4003abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        societe_domaine = input(\"Entrez le nom du domaine/société (ex. 'tesla.com') : \").strip()\n",
    "        scrap_trustpilot(societe_domaine)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nInterruption utilisateur.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
