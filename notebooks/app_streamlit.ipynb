{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80b2b357",
   "metadata": {},
   "source": [
    "-*- coding: utf-8 -*-\n",
    "streamlit run app_streamlit.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be7384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "from sklearn.base import ClassifierMixin\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe5ab0d",
   "metadata": {},
   "source": [
    "=========================\n",
    "Chargement du .env\n",
    "========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666009f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Charge les variables du .env dans os.environ\n",
    "\n",
    "model_dir = os.getenv(\"DATA_MODEL\")\n",
    "\n",
    "if model_dir is None:\n",
    "    raise ValueError(\"Le dossier des mod√®les 'DATA_MODEL' n'est pas d√©fini dans .env ou n'a pas √©t√© charg√©\")\n",
    "\n",
    "\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "ENV_PATH = os.path.join(BASE_DIR, \"..\", \".env\")  # On remonte d'un dossier si besoin\n",
    "load_dotenv(ENV_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b5eba0",
   "metadata": {},
   "source": [
    "R√©cup√©ration des variables d'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ab07da",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_MODEL = os.getenv(\"DATA_MODEL\")  # Chemin vers les mod√®les\n",
    "if DATA_MODEL is None or not os.path.isdir(DATA_MODEL):\n",
    "    st.error(f\"Le dossier des mod√®les '{DATA_MODEL}' n'existe pas ou n'est pas d√©fini.\")\n",
    "    st.stop()\n",
    "\n",
    "TFIDF_NAME = \"tfidf_vectorizer_dual.pkl\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff694794",
   "metadata": {},
   "source": [
    "=========================\n",
    "Utils\n",
    "========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12a8b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache_resource\n",
    "def load_tfidf(path: str):\n",
    "    return joblib.load(path)\n",
    "\n",
    "@st.cache_resource\n",
    "def load_all_models(models_dir: str):\n",
    "    models = {\"note\": {}, \"sentiment\": {}}\n",
    "    pattern = re.compile(r\"(?P<algo>.+)_(?P<task>sentiment|note)\\.pkl$\", re.IGNORECASE)\n",
    "\n",
    "    for pkl_path in glob.glob(os.path.join(models_dir, \"*.pkl\")):\n",
    "        filename = os.path.basename(pkl_path)\n",
    "        if filename == TFIDF_NAME:\n",
    "            continue\n",
    "        m = pattern.match(filename)\n",
    "        if not m:\n",
    "            continue\n",
    "        algo = m.group(\"algo\").lower()\n",
    "        task = m.group(\"task\").lower()\n",
    "        try:\n",
    "            model = joblib.load(pkl_path)\n",
    "            models[task][algo] = model\n",
    "        except Exception as e:\n",
    "            st.warning(f\"Impossible de charger {filename} : {e}\")\n",
    "    return models\n",
    "\n",
    "def mark_negation(text, window=3):\n",
    "    negation_words = {\"ne\", \"pas\", \"plus\", \"jamais\", \"rien\", \"aucun\", \"sans\", \"nul\"}\n",
    "    punctuation = {\".\", \",\", \";\", \":\", \"!\", \"?\"}\n",
    "    stop_words = {\"mais\", \"et\", \"ou\", \"donc\", \"or\", \"ni\", \"car\"}\n",
    "\n",
    "    tokens = text.split()\n",
    "    new_tokens = []\n",
    "    neg_countdown = 0\n",
    "\n",
    "    for tok in tokens:\n",
    "        tok_lower = tok.lower()\n",
    "        if tok_lower in negation_words:\n",
    "            neg_countdown = window\n",
    "            new_tokens.append(tok)\n",
    "        elif neg_countdown > 0:\n",
    "            if tok_lower in punctuation or tok_lower in stop_words:\n",
    "                neg_countdown = 0\n",
    "                new_tokens.append(tok)\n",
    "            else:\n",
    "                new_tokens.append(\"NOT_\" + tok)\n",
    "                neg_countdown -= 1\n",
    "        else:\n",
    "            new_tokens.append(tok)\n",
    "    return \" \".join(new_tokens)\n",
    "\n",
    "def map_sentiment_from_note(note: int):\n",
    "    return \"negatif\" if note == 1 else \"positif\" if note == 5 else \"neutre\"\n",
    "\n",
    "def predict_with_optional_proba(model: ClassifierMixin, X):\n",
    "    y_pred = model.predict(X)\n",
    "    proba = None\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        try:\n",
    "            proba_values = model.predict_proba(X)[0]\n",
    "            classes = model.classes_\n",
    "            proba = {str(c): float(p) for c, p in zip(classes, proba_values)}\n",
    "        except Exception:\n",
    "            pass\n",
    "    return y_pred[0], proba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b08fd2",
   "metadata": {},
   "source": [
    "=========================\n",
    "Chargements\n",
    "========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b58f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_path = os.path.join(DATA_MODEL, TFIDF_NAME)\n",
    "tfidf = load_tfidf(tfidf_path)\n",
    "models = load_all_models(DATA_MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f9c836",
   "metadata": {},
   "source": [
    "=========================\n",
    "UI\n",
    "========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96c7304",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.title(\"üß™ Testeur d'avis ‚Äì multi-mod√®les (note & sentiment)\")\n",
    "\n",
    "with st.sidebar:\n",
    "    st.header(\"‚öôÔ∏è Param√®tres\")\n",
    "    available_tasks = [t for t, d in models.items() if len(d) > 0]\n",
    "    if not available_tasks:\n",
    "        st.error(\"Aucun mod√®le d√©tect√© dans le dossier.\")\n",
    "        st.stop()\n",
    "    task = st.selectbox(\"T√¢che\", available_tasks, format_func=lambda x: \"Pr√©diction de la note (1-5)\" if x == \"note\" else \"Analyse de sentiment\")\n",
    "    algos = list(models[task].keys())\n",
    "    model_name = st.selectbox(\"Mod√®le\", algos)\n",
    "    st.markdown(\"**Mod√®les trouv√©s :**\")\n",
    "    for t, algos_d in models.items():\n",
    "        if algos_d:\n",
    "            st.write(f\"- **{t}** :\", \", \".join(sorted(algos_d.keys())))\n",
    "\n",
    "user_input = st.text_area(\"‚úçÔ∏è Entrez un commentaire √† √©valuer :\", height=150)\n",
    "col1, col2 = st.columns(2)\n",
    "with col1:\n",
    "    do_predict = st.button(\"Pr√©dire\")\n",
    "with col2:\n",
    "    batch_mode = st.toggle(\"Mode batch (1 phrase par ligne)\")\n",
    "\n",
    "if do_predict:\n",
    "    if not user_input.strip():\n",
    "        st.warning(\"Veuillez entrer un commentaire valide.\")\n",
    "        st.stop()\n",
    "    model = models[task][model_name]\n",
    "    phrases = [l.strip() for l in user_input.split(\"\\n\") if l.strip()] if batch_mode else [user_input.strip()]\n",
    "    results = []\n",
    "    for phrase in phrases:\n",
    "        phrase_proc = mark_negation(phrase)\n",
    "        X_vec = tfidf.transform([phrase_proc])\n",
    "        pred, proba = predict_with_optional_proba(model, X_vec)\n",
    "        out = {\"phrase\": phrase, \"prediction\": pred}\n",
    "        if task == \"note\":\n",
    "            try:\n",
    "                out[\"sentiment_from_note\"] = map_sentiment_from_note(int(pred))\n",
    "            except Exception:\n",
    "                pass\n",
    "        if proba:\n",
    "            out[\"proba\"] = proba\n",
    "        results.append(out)\n",
    "    for r in results:\n",
    "        st.write(\"---\")\n",
    "        st.write(f\"**Texte :** {r['phrase']}\")\n",
    "        st.success(f\"**Pr√©diction ({task}) :** {r['prediction']}\")\n",
    "        if \"sentiment_from_note\" in r:\n",
    "            st.info(f\"Sentiment approximatif d√©riv√© de la note : **{r['sentiment_from_note']}**\")\n",
    "        if r.get(\"proba\"):\n",
    "            st.write(\"Probabilit√©s :\")\n",
    "            st.json(r[\"proba\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
