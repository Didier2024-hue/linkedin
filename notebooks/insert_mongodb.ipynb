{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef776d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import ConnectionFailure, PyMongoError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17198ac9",
   "metadata": {},
   "source": [
    "Chargement du .env avec fallback silencieux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594c73d2",
   "metadata": {},
   "source": [
    "Crée le répertoire de logs si inexistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5c2a47",
   "metadata": {},
   "source": [
    "Génère un nom de fichier de log avec timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0402ae",
   "metadata": {},
   "source": [
    "Logger personnalisé avec écriture console + fichier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db5fce0",
   "metadata": {},
   "source": [
    "Ajoute un message de log avec timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb20d104",
   "metadata": {},
   "source": [
    "Sauvegarde les logs dans le fichier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9fffb1",
   "metadata": {},
   "source": [
    "Trouve le fichier d'informations générales le plus récent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d73321",
   "metadata": {},
   "source": [
    "Convertit les clés de répartition en format standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacf516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "BASE_DIR = os.getenv(\"BASE_DIR\", \"/home/datascientest/cde\")\n",
    "SOCIETES_A_TRAITER = ['temu', 'tesla', 'chronopost', 'vinted']\n",
    "LOG_DIR = os.path.join(BASE_DIR, \"log\")\n",
    "\n",
    "def ensure_log_dir():\n",
    "    if not os.path.exists(LOG_DIR):\n",
    "        os.makedirs(LOG_DIR)\n",
    "\n",
    "def get_log_file():\n",
    "    now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    return os.path.join(LOG_DIR, f\"import_mongodb_{now}.log\")\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.log_lines = []\n",
    "\n",
    "    def log(self, msg, level=\"INFO\"):\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        full_msg = f\"[{timestamp}] {level} - {msg}\"\n",
    "        print(full_msg)\n",
    "        self.log_lines.append(full_msg)\n",
    "\n",
    "    def save(self):\n",
    "        with open(self.filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\".join(self.log_lines))\n",
    "\n",
    "def trouver_fichier_info_generale(societe_path, societe_nom):\n",
    "    pattern_dir = re.compile(rf\"scrap_{societe_nom}_\\d{{8}}(_\\d+)?\")\n",
    "    pattern_file = re.compile(rf\"{societe_nom}_informations_generales_\\d{{8}}_\\d{{6}}\\.txt\")\n",
    "\n",
    "    candidats = []\n",
    "    for entry in os.listdir(societe_path):\n",
    "        full_path = os.path.join(societe_path, entry)\n",
    "        if os.path.isdir(full_path) and pattern_dir.fullmatch(entry):\n",
    "            for f in os.listdir(full_path):\n",
    "                if pattern_file.fullmatch(f):\n",
    "                    candidats.append(os.path.join(full_path, f))\n",
    "    \n",
    "    return max(candidats) if candidats else None\n",
    "\n",
    "def convertir_repartition(repartition):\n",
    "    return {\n",
    "        \"1\": repartition.get(\"1 étoile\"),\n",
    "        \"2\": repartition.get(\"2 étoiles\"),\n",
    "        \"3\": repartition.get(\"3 étoiles\"),\n",
    "        \"4\": repartition.get(\"4 étoiles\"),\n",
    "        \"5\": repartition.get(\"5 étoiles\"),\n",
    "        \"total\": repartition.get(\"Total\")\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    ensure_log_dir()\n",
    "    log = Logger(get_log_file())\n",
    "\n",
    "    mongo_uri = os.getenv(\"MONGO_URI\")\n",
    "    mongo_db = os.getenv(\"MONGO_DB\")\n",
    "\n",
    "    if not mongo_uri or not mongo_db:\n",
    "        log.log(\"Configuration MongoDB manquante dans .env\", \"ERROR\")\n",
    "        log.log(\"Assurez-vous d'avoir MONGO_URI et MONGO_DB définis\", \"ERROR\")\n",
    "        log.save()\n",
    "        return\n",
    "\n",
    "    try:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd40a0e",
   "metadata": {},
   "source": [
    "        # Connexion à MongoDB avec vérification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84328b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "        client = MongoClient(mongo_uri, serverSelectionTimeoutMS=5000)\n",
    "        client.server_info()  # Teste la connexion\n",
    "        db = client[mongo_db]\n",
    "        log.log(f\"Connecté à MongoDB | Base: {mongo_db}\", \"SUCCESS\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a74137",
   "metadata": {},
   "source": [
    "        # Vidage des collections avant import (une seule fois au début)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcac0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "        try:\n",
    "            db.societe.delete_many({})\n",
    "            db.avis_trustpilot.delete_many({})\n",
    "            log.log(\"Collections vidées avec succès avant import\", \"INFO\")\n",
    "        except PyMongoError as e:\n",
    "            log.log(f\"Erreur lors du vidage des collections: {str(e)}\", \"ERROR\")\n",
    "            raise\n",
    "\n",
    "        for soc in SOCIETES_A_TRAITER:\n",
    "            societe_path = os.path.join(BASE_DIR, \"data\", \"trustpilot\", soc)\n",
    "            if not os.path.isdir(societe_path):\n",
    "                log.log(f\"Dossier {societe_path} non trouvé, skip.\", \"WARNING\")\n",
    "                continue\n",
    "\n",
    "            fichier_info = trouver_fichier_info_generale(societe_path, soc)\n",
    "            if not fichier_info:\n",
    "                log.log(f\"Fichier infos générales introuvable pour '{soc}', skip.\", \"WARNING\")\n",
    "                continue\n",
    "\n",
    "            log.log(f\"Traitement de {fichier_info}\", \"INFO\")\n",
    "            \n",
    "            try:\n",
    "                with open(fichier_info, encoding='utf-8') as f:\n",
    "                    societe_data = json.load(f)\n",
    "            except json.JSONDecodeError as e:\n",
    "                log.log(f\"Erreur de lecture JSON pour {fichier_info}: {str(e)}\", \"ERROR\")\n",
    "                continue\n",
    "\n",
    "            repartition = convertir_repartition(societe_data.get(\"repartition_avis\", {}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302a9037",
   "metadata": {},
   "source": [
    "            # Insertion des données société"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c82fe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "            try:\n",
    "                db.societe.update_one(\n",
    "                    {\"nom\": soc},\n",
    "                    {\"$set\": {\n",
    "                        \"nom\": societe_data.get(\"societe\", soc),\n",
    "                        \"url\": societe_data.get(\"url\"),\n",
    "                        \"secteur\": societe_data.get(\"secteur\"),\n",
    "                        \"note_globale\": float(societe_data.get(\"note_globale\")) if societe_data.get(\"note_globale\") else None,\n",
    "                        \"nombre_avis\": int(societe_data.get(\"nombre_avis\", 0)),\n",
    "                        \"note_1\": repartition.get(\"1\"),\n",
    "                        \"note_2\": repartition.get(\"2\"),\n",
    "                        \"note_3\": repartition.get(\"3\"),\n",
    "                        \"note_4\": repartition.get(\"4\"),\n",
    "                        \"note_5\": repartition.get(\"5\"),\n",
    "                        \"total_avis\": repartition.get(\"total\"),\n",
    "                        \"date_extraction\": datetime.strptime(societe_data[\"date_extraction\"], \"%Y-%m-%d %H:%M:%S\") if societe_data.get(\"date_extraction\") else None,\n",
    "                        \"nombre_commentaires\": int(societe_data.get(\"nombre_commentaires\", 0)),\n",
    "                        \"pages_scrapees\": societe_data.get(\"pages_scrapees\", \"\")\n",
    "                    }},\n",
    "                    upsert=True\n",
    "                )\n",
    "            except PyMongoError as e:\n",
    "                log.log(f\"Erreur MongoDB lors de l'insertion pour {soc}: {str(e)}\", \"ERROR\")\n",
    "                continue\n",
    "            except ValueError as e:\n",
    "                log.log(f\"Erreur de conversion de données pour {soc}: {str(e)}\", \"ERROR\")\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87531545",
   "metadata": {},
   "source": [
    "            # Traitement des avis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2479e103",
   "metadata": {},
   "outputs": [],
   "source": [
    "            pattern_dir = re.compile(rf\"scrap_{soc}_\\d{{8}}(_\\d+)?\")\n",
    "            total_avis = 0\n",
    "            repertoires_traite = set()\n",
    "\n",
    "            for entry in sorted(os.listdir(societe_path)):\n",
    "                full_path = os.path.join(societe_path, entry)\n",
    "                if os.path.isdir(full_path) and pattern_dir.fullmatch(entry):\n",
    "                    if entry in repertoires_traite:\n",
    "                        log.log(f\"Dossier déjà traité dans cette session: {entry}\", \"WARNING\")\n",
    "                        continue\n",
    "                    repertoires_traite.add(entry)\n",
    "\n",
    "                    log.log(f\"Lecture dossier: {entry}\", \"INFO\")\n",
    "\n",
    "                    for file in os.listdir(full_path):\n",
    "                        if file.endswith(\".json\") and not file.startswith(f\"{soc}_informations_generales\"):\n",
    "                            file_path = os.path.join(full_path, file)\n",
    "                            try:\n",
    "                                with open(file_path, encoding='utf-8') as f:\n",
    "                                    avis_list = json.load(f)\n",
    "                                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b0bc97",
   "metadata": {},
   "source": [
    "                                # Ajout des métadonnées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dd893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                for avis in avis_list:\n",
    "                                    avis.update({\n",
    "                                        \"date_chargement\": datetime.utcnow(),\n",
    "                                        \"id_societe\": soc,\n",
    "                                        \"societe_nom\": societe_data.get(\"societe\", soc)\n",
    "                                    })\n",
    "                                \n",
    "                                if avis_list:\n",
    "                                    db.avis_trustpilot.insert_many(avis_list)\n",
    "                                    total_avis += len(avis_list)\n",
    "                            except json.JSONDecodeError as e:\n",
    "                                log.log(f\"Erreur JSON dans {file_path}: {str(e)}\", \"ERROR\")\n",
    "                            except PyMongoError as e:\n",
    "                                log.log(f\"Erreur MongoDB lors de l'insertion des avis {file_path}: {str(e)}\", \"ERROR\")\n",
    "\n",
    "            log.log(f\"Société traitée: {soc} (Avis importés: {total_avis}, Répertoires traités: {len(repertoires_traite)})\", \"SUCCESS\")\n",
    "\n",
    "    except ConnectionFailure as e:\n",
    "        log.log(f\"Échec de connexion à MongoDB: {str(e)}\", \"ERROR\")\n",
    "    except PyMongoError as e:\n",
    "        log.log(f\"Erreur MongoDB: {str(e)}\", \"ERROR\")\n",
    "    except Exception as e:\n",
    "        log.log(f\"Erreur inattendue: {str(e)}\", \"ERROR\")\n",
    "    finally:\n",
    "        if 'client' in locals():\n",
    "            client.close()\n",
    "            log.log(\"Connexion MongoDB fermée\", \"INFO\")\n",
    "        log.save()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
