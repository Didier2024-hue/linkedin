{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90e46c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a446be0",
   "metadata": {},
   "source": [
    "üîß Chargement des variables d'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2407d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "DATA_EXPORTS = os.getenv(\"DATA_EXPORTS\")\n",
    "DATA_PROCESSED = os.getenv(\"DATA_PROCESSED\")\n",
    "DATA_REPORT = os.getenv(\"DATA_REPORT\")  # nouveau pour le dossier report\n",
    "LOG_DIR = os.getenv(\"LOG_DIR\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab55b8e",
   "metadata": {},
   "source": [
    "üìÅ Fichiers d'entr√©e et sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedf9107",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = os.path.join(DATA_EXPORTS, \"mongo_trustpilot_avis_trustpilot.csv\")\n",
    "OUTPUT_FILE = os.path.join(DATA_PROCESSED, \"export_sentiment_analysis.csv\")\n",
    "STATS_FILE = os.path.join(DATA_PROCESSED, \"stats_sentiment_analysis.csv\")\n",
    "REPORT_PNG = os.path.join(DATA_REPORT, \"report_sentiment_analysis.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c717de80",
   "metadata": {},
   "source": [
    "üìö Log automatique dans le bon r√©pertoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf2375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_filename = os.path.join(LOG_DIR, f\"bert_sentiment_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename, encoding='utf-8'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427d29f4",
   "metadata": {},
   "source": [
    "Cr√©ation des dossiers si absents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795f706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(DATA_PROCESSED, exist_ok=True)\n",
    "os.makedirs(DATA_REPORT, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf0a571",
   "metadata": {},
   "source": [
    "üîÑ Renforcement des n√©gations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1fb925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce_negations(text):\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return text\n",
    "    negations = ['pas', 'plus', 'jamais', 'rien', 'aucun', 'ni', 'nulle part', 'ne', 'non']\n",
    "    tokens = text.split()\n",
    "    result = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        word = tokens[i].lower()\n",
    "        if word in negations:\n",
    "            result.append('[NEG]')\n",
    "            result.append(tokens[i])\n",
    "            j = 1\n",
    "            while j <= 3 and (i + j) < len(tokens):\n",
    "                result.append(tokens[i + j])\n",
    "                j += 1\n",
    "            result.append('[/NEG]')\n",
    "            i += j\n",
    "        else:\n",
    "            result.append(tokens[i])\n",
    "            i += 1\n",
    "    return ' '.join(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339b8dcb",
   "metadata": {},
   "source": [
    "ü§ñ Analyseur BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c511125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.device = -1  # CPU\n",
    "        self.model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "        self.batch_size = 4\n",
    "        self.max_length = 128\n",
    "        logger.info(\"ü§ñ Chargement du mod√®le BERT pour l'analyse de sentiment...\")\n",
    "        try:\n",
    "            self.pipeline = pipeline(\n",
    "                \"sentiment-analysis\",\n",
    "                model=self.model_name,\n",
    "                device=self.device,\n",
    "                truncation=True\n",
    "            )\n",
    "            logger.info(\"‚úÖ Mod√®le BERT charg√© avec succ√®s !\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Erreur lors du chargement du mod√®le : {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def analyze_sentiment(self, text):\n",
    "        try:\n",
    "            if not text or pd.isna(text):\n",
    "                return None, None\n",
    "            result = self.pipeline(text[:self.max_length])\n",
    "            return result[0]['label'], result[0]['score']\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"‚ö†Ô∏è Erreur sur le texte : {text[:50]}... - {str(e)}\")\n",
    "            return None, None\n",
    "\n",
    "    def analyze_batch(self, texts):\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            results = list(tqdm(\n",
    "                executor.map(self.analyze_sentiment, texts),\n",
    "                total=len(texts),\n",
    "                desc=\"üß† Analyse des sentiments\"\n",
    "            ))\n",
    "        return results\n",
    "\n",
    "    def map_label_to_score(self, label):\n",
    "        mapping = {\n",
    "            '1 star': 1,\n",
    "            '2 stars': 2,\n",
    "            '3 stars': 3,\n",
    "            '4 stars': 4,\n",
    "            '5 stars': 5\n",
    "        }\n",
    "        return mapping.get(label, None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109e16a3",
   "metadata": {},
   "source": [
    "üì• Chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bccf5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    logger.info(f\"üìÇ Chargement des donn√©es depuis {filepath}...\")\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        logger.info(f\"‚úÖ Donn√©es charg√©es : {len(df)} avis.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Erreur lors du chargement : {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a69c8c",
   "metadata": {},
   "source": [
    "üßπ Pr√©traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e945d7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    logger.info(\"üßπ Pr√©traitement des donn√©es...\")\n",
    "    df = df.drop_duplicates(subset=['commentaire'])\n",
    "    df['commentaire'] = df['commentaire'].str.strip()\n",
    "    df['commentaire'] = df['commentaire'].replace('', np.nan)\n",
    "    df = df[df['commentaire'].notna()]\n",
    "    logger.info(\"üîÑ Renforcement des n√©gations...\")\n",
    "    df['commentaire'] = df['commentaire'].apply(reinforce_negations)\n",
    "    logger.info(f\"üìä {len(df)} avis apr√®s nettoyage.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8de51a",
   "metadata": {},
   "source": [
    "üìä G√©n√©ration du graphique de distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6883e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sentiment_distribution(stats_df):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    bars = plt.bar(stats_df[\"sentiment_note\"], stats_df[\"count\"], color='skyblue', edgecolor='black')\n",
    "    plt.title(\"R√©partition des avis par note de sentiment (1 √† 5)\", fontsize=14)\n",
    "    plt.xlabel(\"Note de sentiment (1 = tr√®s n√©gatif, 5 = tr√®s positif)\")\n",
    "    plt.ylabel(\"Nombre d'avis\")\n",
    "    plt.xticks(stats_df[\"sentiment_note\"])\n",
    "\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2.0, yval + max(stats_df[\"count\"]) * 0.01, f\"{yval}\", ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(REPORT_PNG)\n",
    "    logger.info(f\"üìà Graphique sauvegard√© dans {REPORT_PNG}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a4f820",
   "metadata": {},
   "source": [
    "üöÄ Programme principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45add681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        df = load_data(INPUT_FILE)\n",
    "        df = preprocess_data(df)\n",
    "\n",
    "        analyzer = SentimentAnalyzer()\n",
    "        texts = df['commentaire'].tolist()\n",
    "        results = analyzer.analyze_batch(texts)\n",
    "\n",
    "        labels, scores = zip(*results)\n",
    "        df['sentiment_label'] = labels\n",
    "        df['sentiment_score'] = scores\n",
    "        df['sentiment_note'] = df['sentiment_label'].apply(analyzer.map_label_to_score)\n",
    "\n",
    "        df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "        logger.info(f\"üíæ R√©sultats sauvegard√©s dans {OUTPUT_FILE}\")\n",
    "        print(f\"\\nüíæ Fichier final : {OUTPUT_FILE} avec {len(df)} lignes\")\n",
    "\n",
    "        stats = df['sentiment_note'].value_counts().sort_index()\n",
    "        logger.info(\"üìà Statistiques des notes de sentiment :\")\n",
    "        logger.info(stats)\n",
    "\n",
    "        stats_df = stats.reset_index()\n",
    "        stats_df.columns = ['sentiment_note', 'count']\n",
    "        stats_df.to_csv(STATS_FILE, index=False, encoding='utf-8-sig')\n",
    "        logger.info(f\"üìä Statistiques sauvegard√©es dans {STATS_FILE}\")\n",
    "        print(\"\\nüìä R√©partition des sentiments :\")\n",
    "        print(stats_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c220646b",
   "metadata": {},
   "source": [
    "        # G√©n√©ration du PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc78783",
   "metadata": {},
   "outputs": [],
   "source": [
    "        plot_sentiment_distribution(stats_df)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Erreur dans le processus principal : {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
